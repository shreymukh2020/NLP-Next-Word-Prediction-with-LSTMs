{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJkZ43rXvs3B"
   },
   "source": [
    "Name: Xiaohong Liu\n",
    "\n",
    "ID: 002727174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install setuptools==65.5.0 \"wheel<0.40.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install d2l==0.17.6\n",
    "!pip install torch==1.12.0\n",
    "!pip install torchvision==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uBjiY5Yscp_f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8pdCEjgScw89"
   },
   "outputs": [],
   "source": [
    "colnames = [\n",
    "    \"ProductID\",\n",
    "    \"ReviewID\",\n",
    "    \"ReviewTitle\",\n",
    "    \"ReviewTime\",\n",
    "    \"Verified\",\n",
    "    \"ReviewContent\",\n",
    "    \"ReviewRating\",\n",
    "]\n",
    "amazon = pd.read_csv(\"Amazon_Comments.csv\", sep=\"^\", header=None, names=colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "aOCB_F3fk4r9",
    "outputId": "ad982cce-f16a-438c-c1ef-24b02c3b922c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewTime</th>\n",
       "      <th>Verified</th>\n",
       "      <th>ReviewContent</th>\n",
       "      <th>ReviewRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>These are hands down the best quality bands fo...</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>False</td>\n",
       "      <td>These are hands down the best quality bands f...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>High Quality Bands</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>False</td>\n",
       "      <td>I just got this set yesterday as well as a se...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>False</td>\n",
       "      <td>My husband uses these and finds them to be go...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The resistance is great. I would agree that th...</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>False</td>\n",
       "      <td>I got these for Christmas and have been using...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>False</td>\n",
       "      <td>Haven\\t had it long enough to use all of the ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  ReviewID                                        ReviewTitle  \\\n",
       "0          1         1  These are hands down the best quality bands fo...   \n",
       "1          1         2                                 High Quality Bands   \n",
       "2          1         3                                         Five Stars   \n",
       "3          1         4  The resistance is great. I would agree that th...   \n",
       "4          1         5                               Good quality product   \n",
       "\n",
       "   ReviewTime  Verified                                      ReviewContent  \\\n",
       "0  2016-01-16     False   These are hands down the best quality bands f...   \n",
       "1  2016-01-22     False   I just got this set yesterday as well as a se...   \n",
       "2  2015-12-27     False   My husband uses these and finds them to be go...   \n",
       "3  2016-01-13     False   I got these for Christmas and have been using...   \n",
       "4  2016-01-20     False   Haven\\t had it long enough to use all of the ...   \n",
       "\n",
       "   ReviewRating  \n",
       "0           5.0  \n",
       "1           5.0  \n",
       "2           5.0  \n",
       "3           4.0  \n",
       "4           5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def pre_process(x):\n",
    "    return re.sub(\n",
    "        \"'ve\",\n",
    "        \" have\",\n",
    "        re.sub(\n",
    "            \"'s\",\n",
    "            \" is\",\n",
    "            re.sub(\n",
    "                \"'m\",\n",
    "                \" am\",\n",
    "                re.sub(\n",
    "                    \"'re\", \" are\", re.sub(\"n't\", \" not\", re.sub(r\"\\\\\", \"'\", x.lower()))\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SNM9OHK5c4Yh"
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "amazon['ReviewContent']= amazon['ReviewContent'].apply(lambda x: pre_process()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing value\n",
    "amazon = amazon[amazon['ReviewContent'] != ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OMxttm5ZdBPs"
   },
   "outputs": [],
   "source": [
    "# separate positive and negative review\n",
    "positive_reviews = amazon[amazon[\"ReviewRating\"].isin([4, 5])][\"ReviewContent\"].tolist()\n",
    "negative_reviews = amazon[amazon[\"ReviewRating\"].isin([1, 2, 3])][\n",
    "    \"ReviewContent\"\n",
    "].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pZG82JTzYKic"
   },
   "outputs": [],
   "source": [
    "# Tokenize the reviews and build a vocabulary\n",
    "tokens = [review.split() for review in negative_reviews + positive_reviews]\n",
    "vocab = {\n",
    "    word: idx\n",
    "    for idx, word in enumerate(set(word for review in tokens for word in review))\n",
    "}\n",
    "\n",
    "# Convert tokens to indices and pad sequences\n",
    "indexed_reviews = [\n",
    "    [vocab[word] for word in review.split()]\n",
    "    for review in negative_reviews + positive_reviews\n",
    "]\n",
    "# padded_reviews = [torch.tensor(review) for review in indexed_reviews]\n",
    "padded_reviews = pad_sequence(\n",
    "    [torch.tensor(review) for review in indexed_reviews], batch_first=True\n",
    ")\n",
    "\n",
    "# Create input and target sequences\n",
    "input_sequences = padded_reviews[:, :-1]\n",
    "target_sequences = padded_reviews[:, 1:]\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_data = TensorDataset(input_sequences, target_sequences)\n",
    "batch_size = 2  # Adjust as needed\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define LSTM and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JNVz5UoYL4D",
    "outputId": "83af00b5-171b-42d7-a8fd-18b342fc73de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5786888599395752\n",
      "Epoch [2/100], Loss: 0.7087135910987854\n",
      "Epoch [3/100], Loss: 0.5375621914863586\n",
      "Epoch [4/100], Loss: 0.2806489169597626\n",
      "Epoch [5/100], Loss: 0.3185948431491852\n",
      "Epoch [6/100], Loss: 0.6932854056358337\n",
      "Epoch [7/100], Loss: 0.21020928025245667\n",
      "Epoch [8/100], Loss: 0.3772299289703369\n",
      "Epoch [9/100], Loss: 0.06534944474697113\n",
      "Epoch [10/100], Loss: 0.5631225109100342\n",
      "Epoch [11/100], Loss: 0.18681462109088898\n",
      "Epoch [12/100], Loss: 0.028448201715946198\n",
      "Epoch [13/100], Loss: 0.1722036451101303\n",
      "Epoch [14/100], Loss: 0.06374713778495789\n",
      "Epoch [15/100], Loss: 0.07380242645740509\n",
      "Epoch [16/100], Loss: 0.0585782565176487\n",
      "Epoch [17/100], Loss: 0.023339075967669487\n",
      "Epoch [18/100], Loss: 0.014055788516998291\n",
      "Epoch [19/100], Loss: 0.010937402956187725\n",
      "Epoch [20/100], Loss: 0.013546172529459\n",
      "Epoch [21/100], Loss: 0.00719092832878232\n",
      "Epoch [22/100], Loss: 0.007199824322015047\n",
      "Epoch [23/100], Loss: 0.01557792630046606\n",
      "Epoch [24/100], Loss: 0.014306537806987762\n",
      "Epoch [25/100], Loss: 0.002040775027126074\n",
      "Epoch [26/100], Loss: 0.017801892012357712\n",
      "Epoch [27/100], Loss: 0.007046059239655733\n",
      "Epoch [28/100], Loss: 0.008424878120422363\n",
      "Epoch [29/100], Loss: 0.0067530227825045586\n",
      "Epoch [30/100], Loss: 0.015331641770899296\n",
      "Epoch [31/100], Loss: 0.0017245194176211953\n",
      "Epoch [32/100], Loss: 0.0004844212962780148\n",
      "Epoch [33/100], Loss: 0.008842634037137032\n",
      "Epoch [34/100], Loss: 0.012654301710426807\n",
      "Epoch [35/100], Loss: 0.006330101750791073\n",
      "Epoch [36/100], Loss: 0.0060062166303396225\n",
      "Epoch [37/100], Loss: 0.016278455033898354\n",
      "Epoch [38/100], Loss: 0.0071440283209085464\n",
      "Epoch [39/100], Loss: 0.0036257142201066017\n",
      "Epoch [40/100], Loss: 0.005873002577573061\n",
      "Epoch [41/100], Loss: 0.008669036440551281\n",
      "Epoch [42/100], Loss: 0.011384712532162666\n",
      "Epoch [43/100], Loss: 0.011529351584613323\n",
      "Epoch [44/100], Loss: 0.011684498749673367\n",
      "Epoch [45/100], Loss: 0.005410113371908665\n",
      "Epoch [46/100], Loss: 0.013916834257543087\n",
      "Epoch [47/100], Loss: 0.008296691812574863\n",
      "Epoch [48/100], Loss: 0.00699502183124423\n",
      "Epoch [49/100], Loss: 0.005835487972944975\n",
      "Epoch [50/100], Loss: 0.005431668367236853\n",
      "Epoch [51/100], Loss: 0.011922826059162617\n",
      "Epoch [52/100], Loss: 0.006035018712282181\n",
      "Epoch [53/100], Loss: 0.007282145321369171\n",
      "Epoch [54/100], Loss: 0.00627563800662756\n",
      "Epoch [55/100], Loss: 0.013235146179795265\n",
      "Epoch [56/100], Loss: 0.01367122121155262\n",
      "Epoch [57/100], Loss: 0.007668685633689165\n",
      "Epoch [58/100], Loss: 0.011958927847445011\n",
      "Epoch [59/100], Loss: 0.0022811295930296183\n",
      "Epoch [60/100], Loss: 0.01292942464351654\n",
      "Epoch [61/100], Loss: 0.0018119399901479483\n",
      "Epoch [62/100], Loss: 0.013046951033174992\n",
      "Epoch [63/100], Loss: 0.008886911906301975\n",
      "Epoch [64/100], Loss: 0.006068392191082239\n",
      "Epoch [65/100], Loss: 0.006373644806444645\n",
      "Epoch [66/100], Loss: 0.002444123849272728\n",
      "Epoch [67/100], Loss: 0.010846132412552834\n",
      "Epoch [68/100], Loss: 0.44038549065589905\n",
      "Epoch [69/100], Loss: 0.5228414535522461\n",
      "Epoch [70/100], Loss: 0.4696175456047058\n",
      "Epoch [71/100], Loss: 0.13949529826641083\n",
      "Epoch [72/100], Loss: 0.11512870341539383\n",
      "Epoch [73/100], Loss: 0.08049359172582626\n",
      "Epoch [74/100], Loss: 0.040127530694007874\n",
      "Epoch [75/100], Loss: 0.07339222729206085\n",
      "Epoch [76/100], Loss: 0.0190361849963665\n",
      "Epoch [77/100], Loss: 0.02432764694094658\n",
      "Epoch [78/100], Loss: 0.02322378382086754\n",
      "Epoch [79/100], Loss: 0.09122028946876526\n",
      "Epoch [80/100], Loss: 0.008008193224668503\n",
      "Epoch [81/100], Loss: 0.01680436171591282\n",
      "Epoch [82/100], Loss: 0.012528367340564728\n",
      "Epoch [83/100], Loss: 0.006959541700780392\n",
      "Epoch [84/100], Loss: 0.00786078255623579\n",
      "Epoch [85/100], Loss: 0.011397910304367542\n",
      "Epoch [86/100], Loss: 0.0071641867980360985\n",
      "Epoch [87/100], Loss: 0.006572688929736614\n",
      "Epoch [88/100], Loss: 0.005104575306177139\n",
      "Epoch [89/100], Loss: 0.014105010777711868\n",
      "Epoch [90/100], Loss: 0.0063776737079024315\n",
      "Epoch [91/100], Loss: 0.00984305888414383\n",
      "Epoch [92/100], Loss: 0.005897349677979946\n",
      "Epoch [93/100], Loss: 0.0061090742237865925\n",
      "Epoch [94/100], Loss: 0.008164503611624241\n",
      "Epoch [95/100], Loss: 0.013242490589618683\n",
      "Epoch [96/100], Loss: 0.008111451752483845\n",
      "Epoch [97/100], Loss: 0.006864486262202263\n",
      "Epoch [98/100], Loss: 0.006505491677671671\n",
      "Epoch [99/100], Loss: 0.011452250182628632\n",
      "Epoch [100/100], Loss: 0.006304529495537281\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Define a custom LSTM-based text generation model\n",
    "# num_epoch is set at 100 and thus this might take a while to train\n",
    "class LSTMTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LSTMTextGenerator, self).__init__()\n",
    "        # Define the layers of the model\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Word embedding layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)  # LSTM layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Fully connected layer (output layer)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Define the forward pass of the model\n",
    "        embedded = self.embedding(x)  # Embed the input sequence\n",
    "        output, (hidden, cell) = self.lstm(embedded, hidden)  # Pass through the LSTM layer\n",
    "        output = self.fc(output)  # Pass through the output layer\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "# Set model hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize the LSTMTextGenerator model\n",
    "model = LSTMTextGenerator(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "\n",
    "# Define the loss function (cross-entropy) and the optimizer (Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_seq in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        hidden = None\n",
    "        output, _ = model(input_seq, hidden)\n",
    "        loss = criterion(output.view(-1, vocab_size), target_seq.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate text using the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bc-0OKdrYL1Y"
   },
   "outputs": [],
   "source": [
    "# Generate text using the trained model (case-insensitive)\n",
    "def generate_text(model, seed_text, vocab, max_length=50):\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model in evaluation mode to disable gradient computation\n",
    "        seed_tokens = (\n",
    "            seed_text.lower().split()\n",
    "        )  # Convert seed text to lowercase and split it into tokens\n",
    "        input_seq = [\n",
    "            vocab[word] for word in seed_tokens\n",
    "        ]  # Convert seed tokens to their corresponding indices in the vocabulary\n",
    "        input_seq = torch.tensor(input_seq).view(\n",
    "            1, -1\n",
    "        )  # Convert the input sequence to a tensor and reshape it to match model input\n",
    "        hidden = None  # Initialize the hidden state (typically used in RNNs)\n",
    "        generated_text = seed_text  # Initialize the generated text with the seed text\n",
    "\n",
    "        for _ in range(max_length):  # Generate text up to the specified maximum length\n",
    "            output, hidden = model(\n",
    "                input_seq, hidden\n",
    "            )  # Get model's output and update hidden state\n",
    "            predicted_idx = torch.multinomial(\n",
    "                torch.exp(output[0, -1, :]), 1\n",
    "            )  # Sample a word index from the model's output\n",
    "            predicted_word = [\n",
    "                word for word, idx in vocab.items() if idx == predicted_idx.item()\n",
    "            ][\n",
    "                0\n",
    "            ]  # Map the index back to a word\n",
    "            generated_text += (\n",
    "                \" \" + predicted_word\n",
    "            )  # Append the predicted word to the generated text\n",
    "            input_seq = torch.cat(\n",
    "                (input_seq, predicted_idx.view(1, -1)), dim=1\n",
    "            )  # Append the predicted index to the input sequence\n",
    "\n",
    "    return generated_text  # Return the generated text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a negative review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKXvr9qxe3Qv",
    "outputId": "44e4c5fa-a50f-44fe-9e70-9f07521fd2e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: they tore up after a little over a year, and i am not very strong... poor quality, also one of the handle got bent (but you can still work out with it). when they tear it can be painful, so i suggest if you must buy this brand, replace every year. measure\n"
     ]
    }
   ],
   "source": [
    "# Example of generating text for poor rating\n",
    "seed_text = \"they tore\"\n",
    "generated_text = generate_text(model, seed_text, vocab)\n",
    "# print(\"Generated Text:\", generated_text)\n",
    "\n",
    "# Remove the remaining repeated words\n",
    "generated_words = generated_text.split()\n",
    "filtered_words = [generated_words[0]]\n",
    "for i in range(1, len(generated_words)):\n",
    "    if generated_words[i] != generated_words[i - 1]:\n",
    "        filtered_words.append(generated_words[i])\n",
    "\n",
    "filtered_generated_text = \" \".join(filtered_words)\n",
    "print(\"Generated Text:\", filtered_generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a positive review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyrJTadWe4Yl",
    "outputId": "f0fee2da-8801-438f-b5a7-a881b214b394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: I just got this set yesterday as well as a set from another company so i could compare the quality. the other set seems to be made pretty well, but these from black mountain are higher quality. the nylon webbing and hardware are heavier and have an overall better quality look. i have been using resistance\n"
     ]
    }
   ],
   "source": [
    "# Example of generating text for high rating\n",
    "seed_text = \"I just got this set yesterday\"\n",
    "generated_text = generate_text(model, seed_text, vocab)\n",
    "#print(\"Generated Text:\", generated_text)\n",
    "\n",
    "# Remove repeated words\n",
    "generated_words = generated_text.split()\n",
    "filtered_words = [generated_words[0]]\n",
    "for i in range(1, len(generated_words)):\n",
    "    if generated_words[i] != generated_words[i - 1]:\n",
    "        filtered_words.append(generated_words[i])\n",
    "\n",
    "filtered_generated_text = \" \".join(filtered_words)\n",
    "print(\"Generated Text:\", filtered_generated_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
